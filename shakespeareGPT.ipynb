{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShakespeareGPT\n",
    "\n",
    "This notebook is a very basic model to generate Shakespearean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "text_data = urllib.request.urlopen('https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt').read().decode('utf-8')\n",
    "print(len(text_data))\n",
    "print(text_data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":z\n",
      "AL-TbeqxyMD&Z$liYI'3pdUmQaEWCvfFBS?JrutjK,RcGoHNw;PX.n!VgOskh \n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(text_data))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building a character level model to generate text. So, here for each character we create encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 8, 17, 17, 48]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda x: [stoi[ch] for ch in x]\n",
    "decode = lambda x: ''.join([itos[i] for i in x])\n",
    "\n",
    "print(encode('hello'))\n",
    "print(decode(encode('hello')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394])\n",
      "tensor([34, 18, 39, 61, 41, 64, 31, 18, 41, 18,  1,  8, 56,  0,  2, 35,  8, 33,\n",
      "        48, 39,  8, 64, 51,  8, 64, 23, 39, 48, 46,  8,  8, 24, 64, 28, 56, 11,\n",
      "        64, 33, 40, 39, 41, 63,  8, 39, 44, 64, 63,  8, 28, 39, 64, 26,  8, 64,\n",
      "        61, 23,  8, 28, 62, 55,  2,  2,  3, 17, 17,  0,  2, 36, 23,  8, 28, 62,\n",
      "        44, 64, 61, 23,  8, 28, 62, 55,  2,  2, 34, 18, 39, 61, 41, 64, 31, 18,\n",
      "        41, 18,  1,  8, 56,  0,  2, 19, 48, 40, 64, 28, 39,  8, 64, 28, 17, 17,\n",
      "        64, 39,  8, 61, 48, 17, 32,  8, 24, 64, 39, 28, 41, 63,  8, 39, 64, 41,\n",
      "        48, 64, 24, 18,  8, 64, 41, 63, 28, 56, 64, 41, 48, 64, 33, 28, 26, 18,\n",
      "        61, 63, 37,  2,  2,  3, 17, 17,  0,  2, 45,  8, 61, 48, 17, 32,  8, 24,\n",
      "        55, 64, 39,  8, 61, 48, 17, 32,  8, 24, 55,  2,  2, 34, 18, 39, 61, 41,\n",
      "        64, 31, 18, 41, 18,  1,  8, 56,  0,  2, 34, 18, 39, 61, 41, 44, 64, 11,\n",
      "        48, 40, 64, 62, 56, 48, 51, 64, 31, 28, 18, 40, 61, 64, 12, 28, 39, 46,\n",
      "        18, 40, 61, 64, 18, 61, 64, 46, 63, 18,  8, 33, 64,  8, 56,  8, 26, 11,\n",
      "        64, 41, 48, 64, 41, 63,  8, 64, 23,  8, 48, 23, 17,  8, 55,  2,  2,  3,\n",
      "        17, 17,  0,  2, 30,  8, 64, 62, 56, 48, 51, 21, 41, 44, 64, 51,  8, 64,\n",
      "        62, 56, 48, 51, 21, 41, 55,  2,  2, 34, 18, 39, 61, 41, 64, 31, 18, 41,\n",
      "        18,  1,  8, 56,  0,  2,  4,  8, 41, 64, 40, 61, 64, 62, 18, 17, 17, 64,\n",
      "        63, 18, 26, 44, 64, 28, 56, 24, 64, 51,  8, 21, 17, 17, 64, 63, 28, 32,\n",
      "         8, 64, 46, 48, 39, 56, 64, 28, 41, 64, 48, 40, 39, 64, 48, 51, 56, 64,\n",
      "        23, 39, 18, 46,  8, 55,  2, 20, 61, 21, 41, 64, 28, 64, 32,  8, 39, 24,\n",
      "        18, 46, 41, 37,  2,  2,  3, 17, 17,  0,  2, 50, 48, 64, 26, 48, 39,  8,\n",
      "        64, 41, 28, 17, 62, 18, 56, 59, 64, 48, 56, 21, 41, 52, 64, 17,  8, 41,\n",
      "        64, 18, 41, 64,  7,  8, 64, 24, 48, 56,  8,  0, 64, 28, 51, 28, 11, 44,\n",
      "        64, 28, 51, 28, 11, 57,  2,  2, 36,  8, 46, 48, 56, 24, 64, 31, 18, 41,\n",
      "        18,  1,  8, 56,  0,  2, 60, 56,  8, 64, 51, 48, 39, 24, 44, 64, 59, 48,\n",
      "        48, 24, 64, 46, 18, 41, 18,  1,  8, 56, 61, 55,  2,  2, 34, 18, 39, 61,\n",
      "        41, 64, 31, 18, 41, 18,  1,  8, 56,  0,  2, 30,  8, 64, 28, 39,  8, 64,\n",
      "        28, 46, 46, 48, 40, 56, 41,  8, 24, 64, 23, 48, 48, 39, 64, 46, 18, 41,\n",
      "        18,  1,  8, 56, 61, 44, 64, 41, 63,  8, 64, 23, 28, 41, 39, 18, 46, 18,\n",
      "        28, 56, 61, 64, 59, 48, 48, 24, 55,  2, 30, 63, 28, 41, 64, 28, 40, 41,\n",
      "        63, 48, 39, 18, 41, 11, 64, 61, 40, 39, 33,  8, 18, 41, 61, 64, 48, 56,\n",
      "        64, 51, 48, 40, 17, 24, 64, 39,  8, 17, 18,  8, 32,  8, 64, 40, 61,  0,\n",
      "        64, 18, 33, 64, 41, 63,  8, 11,  2, 51, 48, 40, 17, 24, 64, 11, 18,  8,\n",
      "        17, 24, 64, 40, 61, 64,  7, 40, 41, 64, 41, 63,  8, 64, 61, 40, 23,  8,\n",
      "        39, 33, 17, 40, 18, 41, 11, 44, 64, 51, 63, 18, 17,  8, 64, 18, 41, 64,\n",
      "        51,  8, 39,  8,  2, 51, 63, 48, 17,  8, 61, 48, 26,  8, 44, 64, 51,  8,\n",
      "        64, 26, 18, 59, 63, 41, 64, 59, 40,  8, 61, 61, 64, 41, 63,  8, 11, 64,\n",
      "        39,  8, 17, 18,  8, 32,  8, 24, 64, 40, 61, 64, 63, 40, 26, 28, 56,  8,\n",
      "        17, 11, 52,  2,  7, 40, 41, 64, 41, 63,  8, 11, 64, 41, 63, 18, 56, 62,\n",
      "        64, 51,  8, 64, 28, 39,  8, 64, 41, 48, 48, 64, 24,  8, 28, 39,  0, 64,\n",
      "        41, 63,  8, 64, 17,  8, 28, 56, 56,  8, 61, 61, 64, 41, 63, 28, 41,  2,\n",
      "        28, 33, 33, 17, 18, 46, 41, 61, 64, 40, 61, 44, 64, 41, 63,  8, 64, 48,\n",
      "         7, 42,  8, 46, 41, 64, 48, 33, 64, 48, 40, 39, 64, 26, 18, 61,  8, 39,\n",
      "        11, 44, 64, 18, 61, 64, 28, 61, 64, 28, 56,  2, 18, 56, 32,  8, 56, 41,\n",
      "        48, 39, 11, 64, 41, 48, 64, 23, 28, 39, 41, 18, 46, 40, 17, 28, 39, 18,\n",
      "        61,  8, 64, 41, 63,  8, 18, 39, 64, 28,  7, 40, 56, 24, 28, 56, 46,  8,\n",
      "        52, 64, 48, 40, 39,  2, 61, 40, 33, 33,  8, 39, 28, 56, 46,  8, 64, 18,\n",
      "        61, 64, 28, 64, 59, 28, 18, 56, 64, 41, 48, 64, 41, 63,  8, 26, 64,  4,\n",
      "         8, 41, 64, 40, 61, 64, 39,  8, 32,  8, 56, 59,  8, 64, 41, 63, 18, 61,\n",
      "        64, 51, 18, 41, 63,  2, 48, 40, 39, 64, 23, 18, 62,  8, 61, 44, 64,  8,\n",
      "        39,  8, 64, 51,  8, 64,  7,  8, 46, 48, 26,  8, 64, 39, 28, 62,  8, 61,\n",
      "         0, 64, 33, 48, 39, 64, 41, 63,  8, 64, 59, 48, 24, 61, 64, 62, 56, 48,\n",
      "        51, 64, 20,  2, 61, 23,  8, 28, 62, 64, 41, 63, 18, 61, 64, 18, 56, 64,\n",
      "        63, 40, 56, 59,  8, 39, 64, 33, 48, 39, 64,  7, 39,  8, 28, 24, 44, 64,\n",
      "        56, 48, 41, 64, 18, 56, 64, 41, 63, 18, 39, 61, 41, 64, 33, 48, 39, 64,\n",
      "        39,  8, 32,  8, 56, 59,  8, 55,  2,  2])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(data = encode(text_data), dtype = torch.long)\n",
    "print(data.shape)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(data) * 0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 8\n",
    "BATCH_SIZE = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([34, 18, 39, 61, 41, 64, 31, 18, 41])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[:BLOCK_SIZE + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: tensor([34]) Target: 18\n",
      "Context: tensor([34, 18]) Target: 39\n",
      "Context: tensor([34, 18, 39]) Target: 61\n",
      "Context: tensor([34, 18, 39, 61]) Target: 41\n",
      "Context: tensor([34, 18, 39, 61, 41]) Target: 64\n",
      "Context: tensor([34, 18, 39, 61, 41, 64]) Target: 31\n",
      "Context: tensor([34, 18, 39, 61, 41, 64, 31]) Target: 18\n",
      "Context: tensor([34, 18, 39, 61, 41, 64, 31, 18]) Target: 41\n"
     ]
    }
   ],
   "source": [
    "# We want the transformer to predict the next character given the previous characters from the range of 1 to BLOCK_SIZE\n",
    "n_embed = 32\n",
    "for i in range(BLOCK_SIZE):\n",
    "    context = train_data[:i + 1]\n",
    "    target = train_data[i + 1]\n",
    "    print(f\"Context: {context} Target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data: torch.Tensor, \n",
    "              batch_size: int, \n",
    "              block_size: int):\n",
    "    index = torch.randint(len(data) - block_size, (batch_size,)) # Randomly selects an index for each batch\n",
    "    x = torch.stack([data[i:i + block_size] for i in index])\n",
    "    y = torch.stack([data[i + 1:i + 1 + block_size] for i in index])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "tensor([[ 8, 64, 41, 63,  8, 64, 33, 28],\n",
      "        [39,  8, 23, 28, 39,  8, 64, 41],\n",
      "        [ 7, 11, 64, 41, 51, 48, 61, 64],\n",
      "        [ 8,  0, 64, 17, 48, 56, 59, 64]])\n",
      "torch.Size([4, 8])\n",
      "tensor([[64, 41, 63,  8, 64, 33, 28, 18],\n",
      "        [ 8, 23, 28, 39,  8, 64, 41, 48],\n",
      "        [11, 64, 41, 51, 48, 61, 64, 28],\n",
      "        [ 0, 64, 17, 48, 56, 59, 64, 26]])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(train_data, BATCH_SIZE, BLOCK_SIZE)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Language Model\n",
    "\n",
    "We start simple with a bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(num_embeddings = vocab_size, embedding_dim = n_embed)\n",
    "        self.positional_embedding = nn.Embedding(num_embeddings = BLOCK_SIZE, embedding_dim = n_embed)\n",
    "        self.linear = nn.Linear(in_features = n_embed, out_features = vocab_size)\n",
    "        # Each row corresponds to a token in the vocabulary. The dimensionality of the embedding is vocab_size here\n",
    "    def forward(self, x, target):\n",
    "        B,T = x.shape\n",
    "        token_embedding = self.token_embedding(x)\n",
    "        pos_embedding = self.positional_embedding(torch.arange(T, device = device))\n",
    "        token_embedding += pos_embedding\n",
    "        logits = self.linear(token_embedding)\n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            target = target.view(B*T)\n",
    "            # If the model is trained well, logits for a given input will be high for the correct target\n",
    "            loss = nn.functional.cross_entropy(logits,target)\n",
    "        return logits, loss\n",
    "    def generate(self, x, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,_ = self.forward(x,None) # Select for all the batches, the last token\n",
    "            logits = logits[:, -1, :] # In all batches, pick the last token\n",
    "            probs = nn.functional.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            x = torch.cat([x,next_token],dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(decode(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "Cell \u001b[1;32mIn[14], line 28\u001b[0m, in \u001b[0;36mBigramLanguageModel.generate\u001b[1;34m(self, x, max_new_tokens)\u001b[0m\n\u001b[0;32m     26\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# In all batches, pick the last token\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m     next_token \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x,next_token],dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1,1), dtype = torch.long).to(device)\n",
    "print(decode(model.generate(x, max_new_tokens = 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 Loss 2.8726345167160034\n",
      "Epoch 2000 Loss 2.5273202818498612\n",
      "Epoch 3000 Loss 2.4952911411684617\n",
      "Epoch 4000 Loss 2.4791210903202456\n",
      "Epoch 5000 Loss 2.480335673691181\n",
      "Epoch 6000 Loss 2.4748337511628877\n",
      "Epoch 7000 Loss 2.4704458322767824\n",
      "Epoch 8000 Loss 2.4693622655477765\n",
      "Epoch 9000 Loss 2.4754364204473105\n",
      "Epoch 10000 Loss 2.4661280247879094\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "model.train()\n",
    "average_loss = 0\n",
    "for epoch in range(10000):\n",
    "    x,y = get_batch(train_data, BATCH_SIZE, BLOCK_SIZE)\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    logits, loss = model(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    average_loss += loss.item()\n",
    "    if (epoch + 1)% 1000 == 0:\n",
    "        average_loss /= 1000\n",
    "        print(f\"Epoch {epoch + 1} Loss {average_loss}\")\n",
    "    optimizer.step()\n",
    "    # print(f\"Epoch {epoch} Loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but I wou, os an werd's Go,\n",
      "Marnutowour fres fit ms alllllin:\n",
      "carefftharar mate INCHAisolendy'seachonice hedegon m; r hy l tr:\n",
      "WICHAMy s, uthoveg:\n",
      "tceryour tho mofene bangertoyTo the is, CLI Tu ck nd, hthevown:\n",
      "He,\n",
      "Toronun me Jur?\n",
      "Wher youn cee e, IIVIS:\n",
      "Thadre p os thacorofu bupr,\n",
      "\n",
      "\n",
      "Fore arpo-f GAs me,\n",
      "\n",
      "Weteeairamavangout d aigm ICotwed Mulend d nd bu th'ss simy thiskederond\n",
      "\n",
      "Tandl hisonothomeliny ad, s,\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(x, max_new_tokens = 400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including Self Attention\n",
    "\n",
    "A given token would have to communicate with previous tokens. A token cannot see the future tokens. So, we will be using self attention to include the context of previous tokens. We can implement this using a weighted sum for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4,8,32 # Batch size, sequence length, channels\n",
    "x = torch.randn(B,T,C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.3561e-01,  2.9674e+00, -8.7036e-01,  ...,  3.1456e-01,\n",
      "           8.7163e-02,  1.7175e-01],\n",
      "         [ 9.4755e-01,  1.1643e+00,  1.0084e-01,  ..., -1.2896e+00,\n",
      "          -5.6144e-01, -3.4468e-02],\n",
      "         [ 2.6413e-01,  5.3581e-01, -3.3713e-01,  ..., -9.9964e-01,\n",
      "          -2.2322e-01, -5.6221e-01],\n",
      "         ...,\n",
      "         [ 1.1283e-01,  5.2472e-02,  1.3156e-01,  ..., -1.7826e-01,\n",
      "           2.8710e-01, -8.2842e-01],\n",
      "         [ 2.5710e-02, -1.1048e-01,  1.7121e-01,  ..., -1.5548e-01,\n",
      "           2.8859e-01, -7.2835e-01],\n",
      "         [ 1.1724e-01, -2.3913e-01,  3.0612e-01,  ..., -3.0154e-01,\n",
      "           4.7531e-01, -7.1948e-01]],\n",
      "\n",
      "        [[-3.6567e-01,  1.0631e+00, -1.2801e+00,  ...,  1.3109e-01,\n",
      "           1.2726e+00, -1.1563e+00],\n",
      "         [-7.8052e-01,  5.7265e-01, -2.0448e-01,  ..., -3.8020e-01,\n",
      "           4.8519e-01, -1.6571e-01],\n",
      "         [-3.9725e-01,  4.9517e-01, -4.3468e-01,  ..., -2.1668e-03,\n",
      "           1.2573e-01, -2.1303e-02],\n",
      "         ...,\n",
      "         [-5.3013e-02,  7.5932e-02, -1.4797e-01,  ..., -4.6662e-01,\n",
      "          -1.6648e-01, -1.2336e-01],\n",
      "         [-5.6101e-02,  1.3949e-01, -7.4790e-02,  ..., -9.3806e-02,\n",
      "          -1.1766e-01, -1.5945e-01],\n",
      "         [-8.4113e-02,  2.7895e-01, -1.7400e-01,  ..., -2.0317e-01,\n",
      "          -8.0100e-02,  2.3264e-03]],\n",
      "\n",
      "        [[-5.2913e-01, -9.5701e-01, -7.8699e-02,  ..., -6.5722e-01,\n",
      "          -8.3353e-01, -1.0094e+00],\n",
      "         [-5.5407e-01, -1.3534e-01, -5.8927e-01,  ...,  1.4633e-01,\n",
      "          -8.4694e-01, -5.0510e-01],\n",
      "         [ 1.3103e-01,  3.8229e-01, -2.2350e-01,  ...,  8.7081e-01,\n",
      "          -7.2420e-01, -4.8626e-01],\n",
      "         ...,\n",
      "         [ 1.2647e-01,  5.1689e-01, -3.0651e-01,  ...,  4.1650e-01,\n",
      "          -3.3024e-01,  2.2460e-01],\n",
      "         [ 1.7022e-01,  3.6963e-01, -2.3906e-01,  ...,  3.6325e-01,\n",
      "          -2.4417e-01,  3.2196e-01],\n",
      "         [ 8.3894e-02,  2.2104e-01, -1.9583e-02,  ...,  4.6612e-01,\n",
      "          -1.2731e-01,  3.5118e-01]],\n",
      "\n",
      "        [[ 3.3694e-01,  1.4870e+00, -3.4668e-01,  ..., -2.1457e-01,\n",
      "           8.2886e-01, -1.9947e-01],\n",
      "         [ 9.9025e-01, -9.2286e-02,  2.1020e-01,  ..., -4.9491e-01,\n",
      "           7.5866e-01, -2.6195e-01],\n",
      "         [ 9.3349e-01, -8.1701e-01,  5.9674e-03,  ..., -6.0049e-01,\n",
      "           3.1338e-01, -4.5077e-01],\n",
      "         ...,\n",
      "         [ 9.5251e-02,  1.0126e-02,  1.6199e-01,  ..., -3.3747e-01,\n",
      "           1.3847e-01, -1.6047e-01],\n",
      "         [-6.9557e-02, -2.6073e-01, -4.9864e-03,  ..., -1.7431e-01,\n",
      "          -2.1710e-02, -1.4761e-01],\n",
      "         [-3.6348e-01, -1.2173e-01,  1.6691e-02,  ..., -2.5242e-01,\n",
      "          -7.0955e-03, -2.9922e-01]]])\n",
      "tensor([[[ 5.3561e-01,  2.9674e+00, -8.7036e-01,  ...,  3.1456e-01,\n",
      "           8.7163e-02,  1.7175e-01],\n",
      "         [ 1.3595e+00, -6.3882e-01,  1.0720e+00,  ..., -2.8937e+00,\n",
      "          -1.2100e+00, -2.4068e-01],\n",
      "         [-1.1027e+00, -7.2120e-01, -1.2131e+00,  ..., -4.1982e-01,\n",
      "           4.5322e-01, -1.6177e+00],\n",
      "         ...,\n",
      "         [-8.0408e-01, -1.3657e+00, -3.0080e-01,  ...,  6.7539e-01,\n",
      "           3.6956e-01, -5.4293e-01],\n",
      "         [-4.9700e-01, -1.0882e+00,  4.0917e-01,  ..., -1.8828e-02,\n",
      "           2.9755e-01, -1.2796e-01],\n",
      "         [ 7.5791e-01, -1.1397e+00,  1.2504e+00,  ..., -1.3239e+00,\n",
      "           1.7824e+00, -6.5739e-01]],\n",
      "\n",
      "        [[-3.6567e-01,  1.0631e+00, -1.2801e+00,  ...,  1.3109e-01,\n",
      "           1.2726e+00, -1.1563e+00],\n",
      "         [-1.1954e+00,  8.2191e-02,  8.7117e-01,  ..., -8.9149e-01,\n",
      "          -3.0223e-01,  8.2492e-01],\n",
      "         [ 3.6930e-01,  3.4021e-01, -8.9507e-01,  ...,  7.5390e-01,\n",
      "          -5.9318e-01,  2.6752e-01],\n",
      "         ...,\n",
      "         [ 1.2356e+00, -3.7836e-01,  7.4508e-01,  ...,  5.3932e-02,\n",
      "          -1.3653e+00,  8.5221e-02],\n",
      "         [-7.4628e-02,  5.2085e-01,  3.6431e-01,  ...,  2.1431e+00,\n",
      "           1.7528e-01, -3.7596e-01],\n",
      "         [-2.8020e-01,  1.2551e+00, -8.6844e-01,  ..., -9.6875e-01,\n",
      "           1.8281e-01,  1.1347e+00]],\n",
      "\n",
      "        [[-5.2913e-01, -9.5701e-01, -7.8699e-02,  ..., -6.5722e-01,\n",
      "          -8.3353e-01, -1.0094e+00],\n",
      "         [-5.7900e-01,  6.8634e-01, -1.0998e+00,  ...,  9.4989e-01,\n",
      "          -8.6034e-01, -8.2968e-04],\n",
      "         [ 1.5012e+00,  1.4175e+00,  5.0804e-01,  ...,  2.3198e+00,\n",
      "          -4.7873e-01, -4.4857e-01],\n",
      "         ...,\n",
      "         [ 3.3868e-01,  1.2491e+00, -4.3429e-01,  ..., -1.7460e-01,\n",
      "          -9.0558e-01,  3.1115e-01],\n",
      "         [ 4.3272e-01, -5.1393e-01,  1.6561e-01,  ...,  4.3748e-02,\n",
      "           2.7222e-01,  9.0612e-01],\n",
      "         [-5.2038e-01, -8.1909e-01,  1.5168e+00,  ...,  1.1862e+00,\n",
      "           6.9073e-01,  5.5577e-01]],\n",
      "\n",
      "        [[ 3.3694e-01,  1.4870e+00, -3.4668e-01,  ..., -2.1457e-01,\n",
      "           8.2886e-01, -1.9947e-01],\n",
      "         [ 1.6435e+00, -1.6716e+00,  7.6708e-01,  ..., -7.7524e-01,\n",
      "           6.8845e-01, -3.2443e-01],\n",
      "         [ 8.1997e-01, -2.2665e+00, -4.0250e-01,  ..., -8.1164e-01,\n",
      "          -5.7718e-01, -8.2842e-01],\n",
      "         ...,\n",
      "         [ 1.1344e+00,  1.9220e+00,  7.0726e-01,  ...,  7.4015e-03,\n",
      "          -2.3554e+00,  1.0897e+00],\n",
      "         [-1.0584e+00, -1.8859e+00, -1.0068e+00,  ...,  8.0464e-01,\n",
      "          -9.8282e-01, -7.0432e-02],\n",
      "         [-2.4210e+00,  8.5131e-01,  1.6844e-01,  ..., -7.9918e-01,\n",
      "           9.5205e-02, -1.3605e+00]]])\n"
     ]
    }
   ],
   "source": [
    "xbow = torch.zeros((B,T,C)) #bow = bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,: t+1] # (t,c)\n",
    "        xbow[b,t] = torch.mean(xprev,dim=0)\n",
    "\n",
    "print(xbow)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the above more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[4., 4., 1.],\n",
      "        [7., 6., 8.],\n",
      "        [7., 1., 1.]])\n",
      "tensor([[4.0000, 4.0000, 1.0000],\n",
      "        [5.5000, 5.0000, 4.5000],\n",
      "        [6.0000, 3.6667, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, dim = 1, keepdim=True)\n",
    "print(a)\n",
    "b = torch.randint(0, 10, (3, 3)).float()\n",
    "print(b)\n",
    "print(torch.matmul(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "averaging_matrix = torch.tril(torch.ones(T, T))\n",
    "averaging_matrix /= torch.sum(averaging_matrix, dim = 1, keepdim = True)\n",
    "print(averaging_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.3561e-01,  2.9674e+00, -8.7036e-01,  ...,  3.1456e-01,\n",
      "           8.7163e-02,  1.7175e-01],\n",
      "         [ 9.4755e-01,  1.1643e+00,  1.0084e-01,  ..., -1.2896e+00,\n",
      "          -5.6144e-01, -3.4468e-02],\n",
      "         [ 2.6413e-01,  5.3581e-01, -3.3713e-01,  ..., -9.9964e-01,\n",
      "          -2.2322e-01, -5.6221e-01],\n",
      "         ...,\n",
      "         [ 1.1283e-01,  5.2472e-02,  1.3156e-01,  ..., -1.7826e-01,\n",
      "           2.8710e-01, -8.2842e-01],\n",
      "         [ 2.5710e-02, -1.1048e-01,  1.7121e-01,  ..., -1.5548e-01,\n",
      "           2.8859e-01, -7.2835e-01],\n",
      "         [ 1.1724e-01, -2.3913e-01,  3.0612e-01,  ..., -3.0154e-01,\n",
      "           4.7531e-01, -7.1948e-01]],\n",
      "\n",
      "        [[-3.6567e-01,  1.0631e+00, -1.2801e+00,  ...,  1.3109e-01,\n",
      "           1.2726e+00, -1.1563e+00],\n",
      "         [-7.8052e-01,  5.7265e-01, -2.0448e-01,  ..., -3.8020e-01,\n",
      "           4.8519e-01, -1.6571e-01],\n",
      "         [-3.9725e-01,  4.9517e-01, -4.3468e-01,  ..., -2.1668e-03,\n",
      "           1.2573e-01, -2.1303e-02],\n",
      "         ...,\n",
      "         [-5.3013e-02,  7.5932e-02, -1.4797e-01,  ..., -4.6662e-01,\n",
      "          -1.6648e-01, -1.2336e-01],\n",
      "         [-5.6101e-02,  1.3949e-01, -7.4790e-02,  ..., -9.3806e-02,\n",
      "          -1.1766e-01, -1.5945e-01],\n",
      "         [-8.4113e-02,  2.7895e-01, -1.7400e-01,  ..., -2.0317e-01,\n",
      "          -8.0100e-02,  2.3264e-03]],\n",
      "\n",
      "        [[-5.2913e-01, -9.5701e-01, -7.8699e-02,  ..., -6.5722e-01,\n",
      "          -8.3353e-01, -1.0094e+00],\n",
      "         [-5.5407e-01, -1.3534e-01, -5.8927e-01,  ...,  1.4633e-01,\n",
      "          -8.4694e-01, -5.0510e-01],\n",
      "         [ 1.3103e-01,  3.8229e-01, -2.2350e-01,  ...,  8.7081e-01,\n",
      "          -7.2420e-01, -4.8626e-01],\n",
      "         ...,\n",
      "         [ 1.2647e-01,  5.1689e-01, -3.0651e-01,  ...,  4.1650e-01,\n",
      "          -3.3024e-01,  2.2460e-01],\n",
      "         [ 1.7022e-01,  3.6963e-01, -2.3906e-01,  ...,  3.6325e-01,\n",
      "          -2.4417e-01,  3.2196e-01],\n",
      "         [ 8.3894e-02,  2.2104e-01, -1.9583e-02,  ...,  4.6612e-01,\n",
      "          -1.2731e-01,  3.5118e-01]],\n",
      "\n",
      "        [[ 3.3694e-01,  1.4870e+00, -3.4668e-01,  ..., -2.1457e-01,\n",
      "           8.2886e-01, -1.9947e-01],\n",
      "         [ 9.9025e-01, -9.2286e-02,  2.1020e-01,  ..., -4.9491e-01,\n",
      "           7.5866e-01, -2.6195e-01],\n",
      "         [ 9.3349e-01, -8.1701e-01,  5.9674e-03,  ..., -6.0049e-01,\n",
      "           3.1338e-01, -4.5077e-01],\n",
      "         ...,\n",
      "         [ 9.5251e-02,  1.0126e-02,  1.6199e-01,  ..., -3.3747e-01,\n",
      "           1.3847e-01, -1.6047e-01],\n",
      "         [-6.9557e-02, -2.6073e-01, -4.9865e-03,  ..., -1.7431e-01,\n",
      "          -2.1710e-02, -1.4761e-01],\n",
      "         [-3.6348e-01, -1.2173e-01,  1.6691e-02,  ..., -2.5242e-01,\n",
      "          -7.0955e-03, -2.9922e-01]]])\n"
     ]
    }
   ],
   "source": [
    "xbow2 = torch.matmul(averaging_matrix, x) # Since x has a batch dimension, pytorch will broadcast the averaging matrix to the batch dimension\n",
    "print(xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "# Another alternative method\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "weights = torch.zeros(T,T)\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = torch.nn.functional.softmax(weights, dim = 1)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n",
      "torch.Size([4, 8, 16])\n",
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(in_features = C, out_features = head_size, bias = False)\n",
    "query = nn.Linear(in_features = C, out_features = head_size, bias = False)\n",
    "value = nn.Linear(in_features = C, out_features = head_size, bias = False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "\n",
    "print(k.shape)\n",
    "print(q.shape)\n",
    "\n",
    "wei = torch.matmul(q, k.transpose(-2,-1)) # B,T,16 * B,16,T = B,T,T\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = torch.nn.functional.softmax(wei, dim = -1)\n",
    "v = value(x)\n",
    "\n",
    "out = torch.matmul(wei, v)\n",
    "print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
